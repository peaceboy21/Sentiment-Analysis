{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\91787\\\\Programming\\\\Projects\\\\Sentiment-Analysis_Roberta\\\\research'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\91787\\\\Programming\\\\Projects\\\\Sentiment-Analysis_Roberta'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path \n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainerConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    model_ckpt: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentimentanalysis.constants import *\n",
    "from sentimentanalysis.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    \n",
    "    def get_model_trainer_config(self) -> ModelTrainerConfig:\n",
    "        config = self.config.model_trainer\n",
    "        params = self.params.TrainingArguments\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        model_trainer_config = ModelTrainerConfig(\n",
    "            root_dir= config.root_dir,\n",
    "            data_path = config.data_path,\n",
    "            model_ckpt = config.model_ckpt\n",
    "        )\n",
    "\n",
    "        return model_trainer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self, config: ModelTrainerConfig):\n",
    "        self.config = config\n",
    "        \n",
    "\n",
    "    def train(self):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"Using device: {device}\")\n",
    "\n",
    "        # Read in data\n",
    "        df = pd.read_csv(\"C:\\\\Users\\\\91787\\\\Programming\\\\Projects\\\\Sentiment-Analysis_Roberta\\\\data\\\\Reviews.csv\")\n",
    "        df = df.head(500)\n",
    "\n",
    "        # Step 1: VADER Sentiment Scoring\n",
    "        sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "        # Run the polarity score on the entire dataset\n",
    "        res = {}\n",
    "        for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "            text = row['Text']\n",
    "            myid = row['Id']\n",
    "            res[myid] = sia.polarity_scores(text)\n",
    "\n",
    "        vaders = pd.DataFrame(res).T\n",
    "        vaders = vaders.reset_index().rename(columns={'index': 'Id'})\n",
    "        vaders = vaders.merge(df, how='left')\n",
    "\n",
    "        # Step 3: Roberta Pretrained Model\n",
    "        MODEL = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "        tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "        model.to(device)\n",
    "\n",
    "        def polarity_scores_roberta(example):\n",
    "            encoded_text = tokenizer(example, return_tensors='pt')\n",
    "            encoded_text = encoded_text.to(device)\n",
    "            \n",
    "            output = model(**encoded_text)\n",
    "            scores = output.logits.detach().cpu().numpy()\n",
    "            scores = softmax(scores, axis=1)  # Ensure softmax is applied along the correct axis\n",
    "            \n",
    "            scores_dict = {\n",
    "                'roberta_neg' : scores[0, 0],  # Adjust indexing\n",
    "                'roberta_neu' : scores[0, 1],  # Adjust indexing\n",
    "                'roberta_pos' : scores[0, 2],  # Adjust indexing\n",
    "            }\n",
    "            return scores_dict\n",
    "\n",
    "        res = {}\n",
    "        for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "            try:\n",
    "                text = row['Text']\n",
    "                myid = row['Id']\n",
    "                vader_result = sia.polarity_scores(text)\n",
    "                vader_result_rename = {}\n",
    "                for key, value in vader_result.items():\n",
    "                    vader_result_rename[f\"vader_{key}\"] = value\n",
    "                roberta_result = polarity_scores_roberta(text)\n",
    "                both = {**vader_result_rename, **roberta_result}\n",
    "                res[myid] = both\n",
    "            except RuntimeError:\n",
    "                print(f'Broke for id {myid}')\n",
    "\n",
    "        results_df = pd.DataFrame(res).T\n",
    "        results_df = results_df.reset_index().rename(columns={'index': 'Id'})\n",
    "        results_df = results_df.merge(df, how='left')\n",
    "\n",
    "        # Save the tokenizer and model\n",
    "        tokenizer.save_pretrained(os.path.join(self.config.root_dir, \"tokenizer\"))\n",
    "        model.save_pretrained(os.path.join(self.config.root_dir, \"pegasus-samsum-model\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-02-10 14:45:49,872: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-02-10 14:45:49,885: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-02-10 14:45:49,887: INFO: common: created directory at: artifacts]\n",
      "[2024-02-10 14:45:49,890: INFO: common: created directory at: artifacts/model_trainer]\n",
      "Using device: cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c783c5e19e6a4bd08b1f0244de03ef6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "301c2737fdc1463fbf34fc0fd8c0bc50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broke for id 83\n",
      "Broke for id 187\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_trainer_config = config.get_model_trainer_config()\n",
    "    model_trainer = ModelTrainer(config=model_trainer_config)\n",
    "    model_trainer.train()\n",
    "except Exception as e:\n",
    "    raise e\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentiment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
